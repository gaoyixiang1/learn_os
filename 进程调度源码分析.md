# 进程调度源码分析

## 进程调度的引入

经过前面的学习，我们知道进程有三种状态，分别是就绪态、运行态及僵死态，它们三种的转换关系如下图所示：

<img src=".\img\process_state.png" alt="process_state" style="zoom:50%;" />

如果处于就绪态的进程有很多，这个时候就需要一个算法，根据进程的紧急程度，重要程度来决策到底先执行哪一个进程，而这个决定进程的执行顺序的算法，就是所说的调度程序，schedule()，这个程序通常在进程状态切换，时间片用完、IO事件发生等情况下被调用，来决定下一个执行的进程。

Linux 的调度程序代码，在内核2.4以前是O（n）算法，后面出现了O（1）算法以及CFS算法，下面是对这几个算法的源码分析：

## O(n)算法

```c
asmlinkage void schedule(void)
{
	struct schedule_data * sched_data;
	struct task_struct *prev, *next, *p;//prev和next分别是调度前以及调度后的进程
	struct list_head *tmp;				//tmp是临时指针变量，指向了双链表
	int this_cpu, c;

	if (!current->active_mm) BUG(); //如果当前的进程的acitive_mm不存在，则出错
need_resched_back:
	prev = current;					//让prev指向当前进程
	this_cpu = prev->processor;	   

	if (in_interrupt())				//如果schedule是在中断服务程序内部执行，就说明发生了错误
		goto scheduling_in_interrupt; 
//schedule()在中断服务程序内部执行，出错

	release_kernel_lock(prev, this_cpu); //释放全局内核锁，并同时开this_cpu的中断

	/* Do "administrative" work here while we don't hold any locks */
	if (softirq_active(this_cpu) & softirq_mask(this_cpu)) //如果软中断的标志位及掩码进行与操作后不为0
		goto handle_softirq;//执行headle_softirq
handle_softirq_back:

	/*
	 * 'sched_data' is protected by the fact that we can run
	 * only one process per CPU.
	 */
    //获取当前CPU的调度数据的指针
	sched_data = & aligned_data[this_cpu].schedule_data;

	spin_lock_irq(&runqueue_lock);   //锁住运行队列，并同时关中断

	/* move an exhausted RR process to be last.. */
	if (prev->policy == SCHED_RR)	//将一个时间片用完的SCHED_RR实时进程放到队列末尾
		goto move_rr_last; 			
//对当前进程做相关处理,为选择下一个进程做好准备。当前进程就是正在运行的进程。可是,当进入 schedule()时,其状态却不一定是 TASK RUNNIG。例如,在exit()系统调用中当前进程的状态可能已被改为 TASK_ZOMBIE;又例如在 wait4()系统调用中,当前进程的状态可能被置为 TASK_INTERRUPTIBLE。因此，如果当前进程处于这些状态中的一种,就要把它从运行队列中删除。  
move_rr_back:
	//根据prev的状态进行相应的处理
	switch (prev->state) {
            
            //如果是可中断的状态，如果该进程还有未处理的信号，则把该进程切换为运行状态
		case TASK_INTERRUPTIBLE:
			if (signal_pending(prev)) {
				prev->state = TASK_RUNNING;
				break;
			}
            //否则，则把该进程从运行队列中删除
		default:
			del_from_runqueue(prev);
            //如果为运行状态，则不做任何处理
		case TASK_RUNNING:
	}
    
	prev->need_resched = 0;

	/*
	 * 下面为调度程序的正文
	 */
    
//如果已经选择的进程其权值为0说明运行队列中所有进的时间片都用完了(队列中肯定没有实时进程，因为其最小权值为 1000),因此,重新计算所有进程的时间片，其中宏操作NICE_TOTICKS就是把优先级 nice 转换为时钟节拍。
    
repeat_schedule:
	/*
	 * Default process to select..
	 */
    //在当前处理器中找到一个空闲进程
	next = idle_task(this_cpu);
	c = -1000;
	if (prev->state == TASK_RUNNING) //如果prev的状态为运行态，则执行still_running
		goto still_running;

    
still_running_back:
    //遍历运行队列
	list_for_each(tmp, &runqueue_head) {
        //获得运行队列每个进程的task_struct
		p = list_entry(tmp, struct task_struct, run_list);
        //单CPU中，该函数总返回1
		if (can_schedule(p, this_cpu)) {
            //weight为p的权值
			int weight = goodness(p, this_cpu, prev->active_mm);
            //如果weight比当前最大的权值大
			if (weight > c)
                //则更新权值最大的进程以及进程的权值
				c = weight, next = p;
		}
	}

	/* Do we need to re-calculate counters? */
    //如果c=0，则说明运行队列中的所有进程权值为0，就是分配给各个进程的时间片用完了，需要重新计算各个进程的时间片
	if (!c)
		goto recalculate;
	/*
	 * from this point on nothing can prevent us from
	 * switching to the next task, save this fact in
	 * sched_data.
	 */
	sched_data->curr = next;
#ifdef CONFIG_SMP
 	next->has_cpu = 1;
	next->processor = this_cpu;
#endif
	spin_unlock_irq(&runqueue_lock);	//对运行队列解锁，并开中断

	if (prev == next)					//如果选中的进程就是原来的进程，则执行same_pocess
		goto same_process;

#ifdef CONFIG_SMP
 	/*
 	 * maintain the per-process 'last schedule' value.
 	 * (this has to be recalculated even if we reschedule to
 	 * the same process) Currently this is only used on SMP,
	 * and it's approximate, so we do not have to maintain
	 * it while holding the runqueue spinlock.
 	 */
 	sched_data->last_schedule = get_cycles();

	/*
	 * We drop the scheduler lock early (it's a global spinlock),
	 * thus we have to lock the previous process from getting
	 * rescheduled during switch_to().
	 */

#endif /* CONFIG_SMP */

	kstat.context_swtch++;		//统计上下文切换的次数
	/*
	 * there are 3 processes which are affected by a context switch:
	 *
	 * prev == .... ==> (last => next)
	 *
	 * It's the 'much more previous' 'prev' that is on next's stack,
	 * but prev is set to (the just run) 'last' process by switch_to().
	 * This might sound slightly confusing but makes tons of sense.
	 */
    
  //准备切换
	prepare_to_switch();
	{
		struct mm_struct *mm = next->mm;
		struct mm_struct *oldmm = prev->active_mm;
        
 //进程地址空间的切换。如果新进程有自己的用户空间，也就是说如果 next->mm与next->active_mm相同，那么,switch_mm()函数就把该进程从内核空间切换到用户空间,也就是加载 next 的页目录。如果新进程无用户空间(next->mm为空)也就是说如果它是一个内核线程，那它就要在内核空间运行。因此,需要借用前一个进程(prev)的地址空间，因为所有进程的内核空间都是共享的。因此,这种借用是有效的。
		if (!mm) {
            //如果是内核线程，则借用prev的地址空间
			if (next->active_mm) BUG();
			next->active_mm = oldmm;
			atomic_inc(&oldmm->mm_count);//mm_count+1
			enter_lazy_tlb(oldmm, next, this_cpu);//把它放进惰性tlb中
		} else {
            //如果是一般的进程，则切换到next的用户空间
			if (next->active_mm != mm) BUG();
			switch_mm(oldmm, mm, next, this_cpu);
		}

		if (!prev->mm) {			//如果切换出去的是内核线程
			prev->active_mm = NULL;	//将他的active_mm置为NULL，即归还它借用的地址空间
			mmdrop(oldmm);			//mm_struct中的共享计数减一
		}
	}

	/*
	 * This just switches the register state and the
	 * stack.
	 */
	switch_to(prev, next, prev);	//进程真正切换，即堆栈的切换
	__schedule_tail(prev);			//置prev->policy的SCHED_YIELD为0
    
//调度前后的进程一样
same_process:
	reacquire_kernel_lock(current);  //针对SMP
	if (current->need_resched)		//如果调度标志被置位
		goto need_resched_back;		//重新开始调度

	return;
    
//重新调度 从运行队列中选择最值得运行的进程，也就是权值最大的进程
recalculate:
	{
		struct task_struct *p;
		spin_unlock_irq(&runqueue_lock); 	//解锁运行队列，并开中断
		read_lock(&tasklist_lock);			//锁住进程的双向队列
		for_each_task(p)					//对系统中的每个进程
			p->counter = (p->counter >> 1) + NICE_TO_TICKS(p->nice);
		read_unlock(&tasklist_lock);		//解锁进程的双向队列
		spin_lock_irq(&runqueue_lock);		//锁住运行队列
	}
	goto repeat_schedule;
//继续运行
    
still_running:
    //获得prev的权值c
	c = goodness(prev, this_cpu, prev->active_mm);
	next = prev; 	//将要调度的程序是prev
	goto still_running_back; //执行still_running_back

handle_softirq:
	do_softirq();//执行do_softirq，主要是执行了
	goto handle_softirq_back;

move_rr_last:
    //如果进程在可运行状态下剩余的的时钟节拍数为0，则令可运行状态下剩余的的时钟节拍数
    //可以根据prev->nice进行计算
	if (!prev->counter) {
		prev->counter = NICE_TO_TICKS(prev->nice);
        //HZ 是指内核时钟频率的一个常量。它表示每秒钟时钟中断的次数，也被称为"滴答"。
        /*
            #if HZ < 200
            #define TICK_SCALE(x)	((x) >> 2)
            #elif HZ < 400
            #define TICK_SCALE(x)	((x) >> 1)
            #elif HZ < 800
            #define TICK_SCALE(x)	(x)
            #elif HZ < 1600
            #define TICK_SCALE(x)	((x) << 1)
            #else
            #define TICK_SCALE(x)	((x) << 2)
            #endif
        	#define NICE_TO_TICKS(nice)	(TICK_SCALE(20-(nice))+1)
        */
		move_last_runqueue(prev);//将prev移到运行队列的末尾
	}
	goto move_rr_back;//执行move_rr_back，即根据进程状态进行处理

scheduling_in_interrupt:
	printk("Scheduling in interrupt\n");
	BUG();
	return;
}
```

## 重点函数分析

### goodness

```c
static inline int goodness(struct task_struct * p, int this_cpu, struct mm_struct *this_mm)
{
	int weight; //进程的权值，是衡量进程是否运行的唯一标准

	/*
	 * select the current process after every other
	 * runnable process, but before the idle thread.
	 * Also, dont trigger a counter recalculation.
	 */
	weight = -1;
    //如果当前进程调度类型为SCHED_YIELD，则执行out 即返回权值-1
	if (p->policy & SCHED_YIELD)
		goto out;

	/*
	 * Non-RT process - normal case first.
	 */
    //如果当前进程调度类型为SCHED_OTHER，即普通进程
	if (p->policy == SCHED_OTHER) {
		/*
		 * Give the process a first-approximation goodness value
		 * according to the number of clock-ticks it has left.
		 *
		 * Don't do any other calculations if the time slice is
		 * over..
		 */
		weight = p->counter; //weight为当前进程的处于运行态时所剩余的时钟节拍数
		if (!weight)		//如果当前进程的处于运行态时所剩余的时钟节拍数为0，则返回当前权值0
			goto out;
			
#ifdef CONFIG_SMP
		/* Give a largish advantage to the same processor...   */
		/* (this is equivalent to penalizing other processors) */
		if (p->processor == this_cpu)
			weight += PROC_CHANGE_PENALTY;
#endif

		/* .. and a slight advantage to the current MM */
        //如果进程的内存空间指针不存在，则进程无用户空间，那么就不必要切换到用户空间
        //或者用户空间就是当前进程的用户空间
        //则让权值+1，
		if (p->mm == this_mm || !p->mm)  //
			weight += 1;
        //否则，让weight+=20-p->nice
        //p->nice是进程的优先级，值从-20---19,值越小，优先级越高，权值越大
		weight += 20 - p->nice;  //weight从0---40
		goto out;//执行out，返回权值
	}

	/*
	 * Realtime process, select the first one on the
	 * runqueue (taking priorities within processes
	 * into account).
	 */
    //对于实时进程，weight=100+p->rt_priority，其优先级取决于实时进程的优先级，至少1000
	weight = 1000 + p->rt_priority;
out:
	return weight;
}

```

通过对goodness这个函数的分析，知道这个函数就是来确定进程的权值，从而衡量一个处于可运行状态的进程值得运行的程度。

### do_softirq

```c
asmlinkage void do_softirq()
{
	int cpu = smp_processor_id();//cpu用于保存当前的cpu编号
	__u32 active, mask;

	if (in_interrupt()) //如果是在中断服务程序内部执行此函数，则什么也不做
		return;

	local_bh_disable();//用于禁用当前处理器的软中断

	local_irq_disable();//用于解除禁用当前处理器的软中断
	mask = softirq_mask(cpu);//mask用于获取当前cpu软中断的掩码
	active = softirq_active(cpu) & mask;//active是获得当前cpu软中断事件(当前软中断标志位和掩码进行与操作)
//判断是否有正在处理的中断事件，有的话就定义一个指针h，遍历中断数组
	if (active) {
		struct softirq_action *h;						
                                         //  struct softirq_action
                                        //{
                                         //   void	(*action)(struct softirq_action *);
                                         //   void	*data;
                                        //};

restart:
		/* Reset active bitmask before enabling irqs */
		softirq_active(cpu) &= ~active;//将当前正在处理的软中断事件清0

		local_irq_enable();//启用本地中断
	
		h = softirq_vec;//h执行软中断数组的第一个元素
		mask &= ~active;//mask中清掉正在处理的软中断事件

		do {
			if (active & 1) //判断当前软中断事件是否要被处理
				h->action(h);//调用h的处理函数
			h++;//遍历
			active >>= 1;//右移一位，丢弃已经处理过的事件
		} while (active);

		local_irq_disable();//禁用本地中断

		active = softirq_active(cpu);//active为更新后的软中断标志位
		if ((active &= mask) != 0)//更新后仍有要处理的软中断事件
			goto retry;//继续执行restart
	}

	local_bh_enable();//启用本地中断

	/* Leave with locally disabled hard irqs. It is critical to close
	 * window for infinite recursion, while we help local bh count,
	 * it protected us. Now we are defenceless.
	 */
	return;

retry:
	goto restart;
}


```

通过对do_softirq的分析，得知，这个函数是处理软中断事件的，也就是执行相应的处理函数。首先获取当前 CPU 的编号。然后禁用当前处理器的本地软中断和本地中断。再获取当前 CPU 的软中断掩码和正在处理的软中断事件。如果有正在处理的软中断事件，则依次处理每个事件。当处理完所有软中断事件后，重新启用本地中断和本地软中断，并返回。

### mm和active_mm

在之前学习的进程部分，进程的结构体如下：

```c
struct task_struct {
    struct mm_struct *active_mm;
    struct mm_struct *mm;
    ...
    }
```

我们知道,Linux 简化了分段机制使得地址与线性地址总是一致的。线性空间在 32 位下有4GB 的固定大小，也就是 Linux 的虚拟地址空间也这么大。Linux 内核将这4GB的空间分为两部分：最高的 1GB供内核使用称为“内核空间”。而较低的 3GB供各个进程使用，称为“用户空间”。因为每个进程可以通过系统调用进入内核，因此，Linux内核空间由系统内的所有进程共享。而在这里要注意内核线程是只能运行在内核空间，而普通进程可以运行在用户空间和内核空间(通过系统调用)。

<img src=".\img\mm.png" alt="mm" style="zoom:67%;" />

在这块，mm和active_mm都是指向内存的，mm是用来描述进程的整个用户空间的。那么active_mm指的是啥？

#### 真实地址空间和匿名地址空间

两者的的区别在于匿名地址空间不关心用户级的页表，当我们做一个上下文切换到匿名地址空间时我们只保留之前的活跃地址空间活跃。`task_struct->mm`”指向“真实地址空间”。对于匿名进程，它“真实地址空间”也就是`task_struct->mm将为NULL`，出于逻辑原因，一个匿名进程没有一个真正的地址空间。然而，我们也需要知道匿名地址空间他的真正的地址，这样就需要我们的地址空间为这样一个匿名用户“偷”取一个地址。所以就有了`task_struct->active_mm`来显示当前活动的地址空间是什么。这样的话，对于一个具有真实地址空间的进程(即`task_struct->mm`是非null)的active_mm显然必须与实际的地址空间是相同的一个。对于匿名进程，`task_struct->mm == NULL`，而`task_struct->active_mm`为“借来的”`mm`，匿名进程正在运行。当匿名进程被调度离开，借用的地址空间将会返还给原来的进程，并且清除这一字段。

也就是说，匿名进程没有自己的真正地址空间，它必须得通过借用具有真实地址空间的进程的地址空间，也就是说借来的空间是`task_active_mm`

#### mm_users和mm_count

为了支持上述的这些，`struct mm_struct`中有两个计数器`mm_users`和`mm_count`。

```
struct mm_struct {
	atomic_t mm_users;			/* How many users with user space? */
	atomic_t mm_count;			/* How many references to "struct mm_struct" (users count as 1) */

};
```

`mm_users`表示共享地址空间的进程数目，其实也就是有多少“真实的地址空间用户”，`mm_count`计数器表示对`mm_srtuct`的引用计数，也就是上面所说的匿名用户的数量加上1。通常至少有一个真正的用户，因为匿名进程必须要借用真实用户进程的`mm`





